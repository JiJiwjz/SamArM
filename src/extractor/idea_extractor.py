"""
è®ºæ–‡æ ¸å¿ƒæ€æƒ³æå–æ¨¡å—
è´Ÿè´£å¯¹è®ºæ–‡è¿›è¡ŒAIæ€»ç»“å’Œæ€æƒ³æå–
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import json

from .deepseek_client import DeepSeekClient, DeepSeekBatchProcessor

logger = logging.getLogger(__name__)


@dataclass
class ExtractedIdea:
    """æå–çš„è®ºæ–‡æ€æƒ³"""
    paper_id: str
    title: str
    authors: List[str]
    summary: str                    # åŸå§‹æ‘˜è¦
    ai_summary: str                 # AIç”Ÿæˆçš„æ€»ç»“
    key_points: Optional[str]       # å…³é”®è¦ç‚¹
    
    # ğŸ†• è®ºæ–‡è´¨é‡è¯„ä¼°
    quality_score: Optional[int] = None     # è´¨é‡è¯„åˆ† 1-10
    quality_level: Optional[str] = None     # è´¨é‡ç­‰çº§
    quality_reasoning: Optional[str] = None # è¯„ä¼°ç†ç”±
    
    extraction_status: str = 'unknown'      # success|fallback|error
    extraction_error: Optional[str] = None  # é”™è¯¯ä¿¡æ¯
    extraction_time: str = ''               # æå–æ—¶é—´
    
    # åŸè®ºæ–‡ä¿¡æ¯
    published: str = ''
    arxiv_url: str = ''
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class IdeaExtractor:
    """è®ºæ–‡æ€æƒ³æå–å™¨"""
    
    def __init__(self, deepseek_config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ€æƒ³æå–å™¨
        
        Args:
            deepseek_config: DeepSeeké…ç½®å­—å…¸
        """
        api_key = deepseek_config.get('api_key')
        if not api_key:
            raise ValueError("DeepSeek APIå¯†é’¥æœªé…ç½®ï¼")
        
        self.client = DeepSeekClient(
            api_key=api_key,
            api_url=deepseek_config.get('api_url', 'https://api.deepseek.com/v1'),
            model=deepseek_config.get('model', 'deepseek-chat'),
            timeout=deepseek_config.get('timeout', 30)
        )
        
        self.system_prompt = deepseek_config.get('system_prompt', 
            """ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡æ€»ç»“ä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡æ€»ç»“ä»¥ä¸‹è®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³ï¼Œ
åŒ…æ‹¬ï¼š1) ç ”ç©¶é—®é¢˜ 2) æ–¹æ³•åˆ›æ–° 3) ä¸»è¦è´¡çŒ® 4) å®éªŒç»“æœã€‚
æ§åˆ¶åœ¨200-300å­—ä»¥å†…ï¼Œè¯­è¨€ç®€æ´å­¦æœ¯ã€‚""")
        
        logger.info("è®ºæ–‡æ€æƒ³æå–å™¨å·²åˆå§‹åŒ–")
    
    def _fallback_summary(self, original_summary: str, max_len: int = 300) -> str:
        """å¤‡é€‰æ€»ç»“æ–¹æ¡ˆï¼šæˆªæ–­åŸå§‹æ‘˜è¦"""
        if len(original_summary) <= max_len:
            return original_summary
        return original_summary[:max_len] + "..."
    
    async def extract_single_paper(self, paper: Dict[str, Any]) -> ExtractedIdea:
        """
        å¼‚æ­¥æå–å•ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³ï¼ˆåŒ…å«è¯„ä¼°ï¼‰
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯å­—å…¸
        
        Returns:
            æå–çš„æ€æƒ³å¯¹è±¡
        """
        paper_id = paper.get('paper_id', 'unknown')
        
        try:
            # å¹¶å‘æ‰§è¡Œæ€»ç»“å’Œè¯„ä¼°
            summary_task = self.client.summarize_paper(
                paper.get('title', ''),
                paper.get('summary', ''),
                self.system_prompt
            )
            
            eval_task = self.client.evaluate_paper_quality(
                paper.get('title', ''),
                paper.get('summary', ''),
                paper.get('authors', [])
            )
            
            ai_summary, eval_result = await asyncio.gather(summary_task, eval_task)
            
            # å¤„ç†æ€»ç»“ç»“æœ
            if ai_summary:
                extraction_status = 'success'
                extraction_error = None
                logger.info(f"âœ… æ€æƒ³æå–æˆåŠŸ: {paper_id}")
            else:
                ai_summary = self._fallback_summary(paper.get('summary', ''))
                extraction_status = 'fallback'
                extraction_error = 'APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ'
                logger.warning(f"âš ï¸  APIå¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ: {paper_id}")
            
            # å¤„ç†è¯„ä¼°ç»“æœ
            if eval_result:
                quality_score = eval_result.get('quality_score')
                quality_level = eval_result.get('quality_level')
                quality_reasoning = eval_result.get('reasoning')
                logger.info(f"ğŸ“Š è®ºæ–‡è¯„ä¼°: {paper_id} - {quality_level} ({quality_score}/10)")
            else:
                quality_score = None
                quality_level = None
                quality_reasoning = None
                logger.warning(f"âš ï¸  è®ºæ–‡è¯„ä¼°å¤±è´¥: {paper_id}")
            
        except Exception as e:
            logger.error(f"âŒ æå–å¤±è´¥ {paper_id}: {e}")
            ai_summary = self._fallback_summary(paper.get('summary', ''))
            extraction_status = 'error'
            extraction_error = str(e)
            quality_score = None
            quality_level = None
            quality_reasoning = None
        
        return ExtractedIdea(
            paper_id=paper_id,
            title=paper.get('title', ''),
            authors=paper.get('authors', []),
            summary=paper.get('summary', ''),
            ai_summary=ai_summary,
            key_points=None,
            quality_score=quality_score,
            quality_level=quality_level,
            quality_reasoning=quality_reasoning,
            extraction_status=extraction_status,
            extraction_error=extraction_error,
            extraction_time=datetime.now().isoformat(),
            published=paper.get('published', ''),
            arxiv_url=paper.get('arxiv_url', '')
        )
    
    async def extract_batch_papers(self, papers: List[Dict[str, Any]], 
                                   batch_size: int = 3) -> Tuple[List[ExtractedIdea], Dict[str, Any]]:
        """
        æ‰¹é‡æå–è®ºæ–‡æ€æƒ³ï¼ˆå¼‚æ­¥ï¼Œå¸¦è¯„ä¼°ï¼‰
        
        âš ï¸ æ–¹æ³•åå¿…é¡»æ˜¯ extract_batch_papers ä»¥å…¼å®¹ daily_job.py
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        Returns:
            (æå–çš„æ€æƒ³åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
        """
        start_time = datetime.now()
        processor = DeepSeekBatchProcessor(self.client, batch_size=batch_size)
        
        summaries, evaluations = await processor.process_papers_with_evaluation(
            papers, self.system_prompt
        )
        
        results = []
        success_count = 0
        fallback_count = 0
        error_count = 0
        
        for (paper, ai_summary), (_, eval_result) in zip(summaries, evaluations):
            paper_id = paper.get('paper_id', 'unknown')
            
            # å¤„ç†æ€»ç»“
            if ai_summary:
                extraction_status = 'success'
                extraction_error = None
                success_count += 1
            else:
                ai_summary = self._fallback_summary(paper.get('summary', ''))
                extraction_status = 'fallback'
                extraction_error = 'APIè°ƒç”¨å¤±è´¥'
                fallback_count += 1
            
            # å¤„ç†è¯„ä¼°
            if eval_result:
                quality_score = eval_result.get('quality_score')
                quality_level = eval_result.get('quality_level')
                quality_reasoning = eval_result.get('reasoning')
            else:
                quality_score = None
                quality_level = None
                quality_reasoning = None
            
            results.append(ExtractedIdea(
                paper_id=paper_id,
                title=paper.get('title', ''),
                authors=paper.get('authors', []),
                summary=paper.get('summary', ''),
                ai_summary=ai_summary,
                key_points=None,
                quality_score=quality_score,
                quality_level=quality_level,
                quality_reasoning=quality_reasoning,
                extraction_status=extraction_status,
                extraction_error=extraction_error,
                extraction_time=datetime.now().isoformat(),
                published=paper.get('published', ''),
                arxiv_url=paper.get('arxiv_url', '')
            ))
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        stats = {
            'success': success_count,
            'fallback': fallback_count,
            'error': error_count,
            'total': len(results),
            'processing_time': processing_time
        }
        
        logger.info(f"æ‰¹é‡æå–å®Œæˆï¼šå…± {len(results)} ç¯‡ (æˆåŠŸ:{success_count} å¤‡é€‰:{fallback_count} å¤±è´¥:{error_count})")
        return results, stats
